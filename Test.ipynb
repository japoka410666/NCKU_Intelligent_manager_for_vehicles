{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c87bb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c900bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#define a preprocessing function\n",
    "def pre_func(image):\n",
    "    image = np.array(image)\n",
    "    converted_img = (image - 128.0) / 128\n",
    "    return converted_img\n",
    "\n",
    "#load images and labels\n",
    "img_gen = ImageDataGenerator(rotation_range=30,\n",
    "                             width_shift_range=0.3,\n",
    "                             height_shift_range=0.3,\n",
    "                             brightness_range=[0.2,1.0],\n",
    "                             validation_split=0.2,\n",
    "                             preprocessing_function=pre_func,\n",
    "                             dtype='float32')\n",
    "\n",
    "train_image_gen = img_gen.flow_from_directory(\"data\",target_size=(64,64),color_mode='grayscale',batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9ac0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(64,64,1)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),   # 1st layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),                                        # 2nd layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),                                        # 3rd layer\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "#    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "#    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8000eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 323,491\n",
      "Trainable params: 323,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afd1c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3acda15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Closed': 0, 'Opened': 1, 'Un_recognized': 2}\n"
     ]
    }
   ],
   "source": [
    "print(train_image_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f6dc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-fc309d176cfd>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.1134 - accuracy: 0.3367\n",
      "Epoch 2/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.1141 - accuracy: 0.3469\n",
      "Epoch 3/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.0880 - accuracy: 0.3265\n",
      "Epoch 4/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.1171 - accuracy: 0.4082\n",
      "Epoch 5/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.0972 - accuracy: 0.3980\n",
      "Epoch 6/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.1189 - accuracy: 0.3367\n",
      "Epoch 7/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 1.0989 - accuracy: 0.4184\n",
      "Epoch 8/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 1.0809 - accuracy: 0.3878\n",
      "Epoch 9/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.9750 - accuracy: 0.5204\n",
      "Epoch 10/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.8694 - accuracy: 0.4694\n",
      "Epoch 11/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.9157 - accuracy: 0.5204\n",
      "Epoch 12/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.8174 - accuracy: 0.5816\n",
      "Epoch 13/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.7682 - accuracy: 0.5918\n",
      "Epoch 14/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.8201 - accuracy: 0.5714\n",
      "Epoch 15/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7460 - accuracy: 0.6020\n",
      "Epoch 16/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.8408 - accuracy: 0.4490\n",
      "Epoch 17/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.7392 - accuracy: 0.5510\n",
      "Epoch 18/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7372 - accuracy: 0.5918\n",
      "Epoch 19/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7283 - accuracy: 0.6633\n",
      "Epoch 20/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7979 - accuracy: 0.6327\n",
      "Epoch 21/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7369 - accuracy: 0.6327\n",
      "Epoch 22/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7561 - accuracy: 0.5612\n",
      "Epoch 23/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7754 - accuracy: 0.6020\n",
      "Epoch 24/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6719 - accuracy: 0.6837 0s - loss: 0.6766 - accuracy: \n",
      "Epoch 25/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.8218 - accuracy: 0.5918\n",
      "Epoch 26/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6720 - accuracy: 0.6429\n",
      "Epoch 27/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6661 - accuracy: 0.7041\n",
      "Epoch 28/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6523 - accuracy: 0.6837\n",
      "Epoch 29/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5845 - accuracy: 0.6939\n",
      "Epoch 30/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7576 - accuracy: 0.5918\n",
      "Epoch 31/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6194 - accuracy: 0.6429\n",
      "Epoch 32/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6512 - accuracy: 0.7041\n",
      "Epoch 33/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5917 - accuracy: 0.6939\n",
      "Epoch 34/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6051 - accuracy: 0.7143\n",
      "Epoch 35/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.7525 - accuracy: 0.6429\n",
      "Epoch 36/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6455 - accuracy: 0.6633\n",
      "Epoch 37/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5426 - accuracy: 0.7041\n",
      "Epoch 38/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5518 - accuracy: 0.7245\n",
      "Epoch 39/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5775 - accuracy: 0.7245\n",
      "Epoch 40/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5832 - accuracy: 0.7449\n",
      "Epoch 41/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5616 - accuracy: 0.7857\n",
      "Epoch 42/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6998 - accuracy: 0.7347\n",
      "Epoch 43/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5818 - accuracy: 0.7551\n",
      "Epoch 44/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.8726 - accuracy: 0.6224\n",
      "Epoch 45/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4895 - accuracy: 0.7245\n",
      "Epoch 46/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6167 - accuracy: 0.7347\n",
      "Epoch 47/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5272 - accuracy: 0.7143\n",
      "Epoch 48/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6047 - accuracy: 0.6633\n",
      "Epoch 49/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6500 - accuracy: 0.6633\n",
      "Epoch 50/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5751 - accuracy: 0.6837\n",
      "Epoch 51/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4883 - accuracy: 0.7449\n",
      "Epoch 52/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4549 - accuracy: 0.8061\n",
      "Epoch 53/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5654 - accuracy: 0.7143\n",
      "Epoch 54/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5627 - accuracy: 0.7245\n",
      "Epoch 55/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4017 - accuracy: 0.7959\n",
      "Epoch 56/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.6258 - accuracy: 0.7245 0s - loss: 0.6246 - accuracy: 0.73\n",
      "Epoch 57/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.6003 - accuracy: 0.7143\n",
      "Epoch 58/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4403 - accuracy: 0.8265\n",
      "Epoch 59/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4666 - accuracy: 0.8469\n",
      "Epoch 60/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5430 - accuracy: 0.7755\n",
      "Epoch 61/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5421 - accuracy: 0.7449\n",
      "Epoch 62/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4890 - accuracy: 0.8061\n",
      "Epoch 63/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.5042 - accuracy: 0.7551\n",
      "Epoch 64/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.3817 - accuracy: 0.8469\n",
      "Epoch 65/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4245 - accuracy: 0.8061\n",
      "Epoch 66/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4130 - accuracy: 0.8265\n",
      "Epoch 67/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.5070 - accuracy: 0.7857\n",
      "Epoch 68/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4388 - accuracy: 0.7653\n",
      "Epoch 69/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4470 - accuracy: 0.7959\n",
      "Epoch 70/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4875 - accuracy: 0.7653\n",
      "Epoch 71/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4914 - accuracy: 0.8469 0s - loss: 0.4581 - accura\n",
      "Epoch 72/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.4355 - accuracy: 0.8265\n",
      "Epoch 73/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5832 - accuracy: 0.7755\n",
      "Epoch 74/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.3104 - accuracy: 0.8776\n",
      "Epoch 75/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2871 - accuracy: 0.9082\n",
      "Epoch 76/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.5082 - accuracy: 0.7755\n",
      "Epoch 77/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5390 - accuracy: 0.7551\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 2s 20ms/step - loss: 0.3592 - accuracy: 0.8878\n",
      "Epoch 79/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2896 - accuracy: 0.9082\n",
      "Epoch 80/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4945 - accuracy: 0.8265\n",
      "Epoch 81/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4337 - accuracy: 0.8061\n",
      "Epoch 82/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3341 - accuracy: 0.8673\n",
      "Epoch 83/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3608 - accuracy: 0.8673\n",
      "Epoch 84/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3211 - accuracy: 0.8673\n",
      "Epoch 85/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3437 - accuracy: 0.8367\n",
      "Epoch 86/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2016 - accuracy: 0.9286\n",
      "Epoch 87/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2535 - accuracy: 0.8673\n",
      "Epoch 88/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4192 - accuracy: 0.8571\n",
      "Epoch 89/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4146 - accuracy: 0.8163\n",
      "Epoch 90/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.4684 - accuracy: 0.8163\n",
      "Epoch 91/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2767 - accuracy: 0.8980\n",
      "Epoch 92/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3133 - accuracy: 0.8878\n",
      "Epoch 93/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4164 - accuracy: 0.8571\n",
      "Epoch 94/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3560 - accuracy: 0.8776\n",
      "Epoch 95/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.4364 - accuracy: 0.8571\n",
      "Epoch 96/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2143 - accuracy: 0.9286\n",
      "Epoch 97/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.5423 - accuracy: 0.7959\n",
      "Epoch 98/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2252 - accuracy: 0.9184\n",
      "Epoch 99/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2707 - accuracy: 0.9082\n",
      "Epoch 100/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2672 - accuracy: 0.9082\n",
      "Epoch 101/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3497 - accuracy: 0.8776\n",
      "Epoch 102/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3778 - accuracy: 0.8061\n",
      "Epoch 103/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3868 - accuracy: 0.8469\n",
      "Epoch 104/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3343 - accuracy: 0.8878\n",
      "Epoch 105/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3408 - accuracy: 0.8571\n",
      "Epoch 106/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.1780 - accuracy: 0.9286\n",
      "Epoch 107/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3454 - accuracy: 0.8980\n",
      "Epoch 108/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2534 - accuracy: 0.8776\n",
      "Epoch 109/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2257 - accuracy: 0.8980\n",
      "Epoch 110/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3149 - accuracy: 0.8776\n",
      "Epoch 111/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3898 - accuracy: 0.8878\n",
      "Epoch 112/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3350 - accuracy: 0.8673\n",
      "Epoch 113/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2266 - accuracy: 0.9082\n",
      "Epoch 114/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.5385 - accuracy: 0.7755\n",
      "Epoch 115/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3158 - accuracy: 0.8673\n",
      "Epoch 116/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1268 - accuracy: 0.9694\n",
      "Epoch 117/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.3069 - accuracy: 0.9184\n",
      "Epoch 118/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2962 - accuracy: 0.8980\n",
      "Epoch 119/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.2597 - accuracy: 0.8878\n",
      "Epoch 120/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.1560 - accuracy: 0.9388\n",
      "Epoch 121/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.1954 - accuracy: 0.8980\n",
      "Epoch 122/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.3676 - accuracy: 0.8469\n",
      "Epoch 123/150\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.3530 - accuracy: 0.8571\n",
      "Epoch 124/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.3357 - accuracy: 0.8673\n",
      "Epoch 125/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.3597 - accuracy: 0.8265\n",
      "Epoch 126/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.1561 - accuracy: 0.9388\n",
      "Epoch 127/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2113 - accuracy: 0.9388\n",
      "Epoch 128/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2569 - accuracy: 0.9082\n",
      "Epoch 129/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.1470 - accuracy: 0.9592\n",
      "Epoch 130/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3021 - accuracy: 0.8878\n",
      "Epoch 131/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2397 - accuracy: 0.8980\n",
      "Epoch 132/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2487 - accuracy: 0.9388\n",
      "Epoch 133/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2333 - accuracy: 0.9082\n",
      "Epoch 134/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2214 - accuracy: 0.9388\n",
      "Epoch 135/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.1641 - accuracy: 0.9286\n",
      "Epoch 136/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2193 - accuracy: 0.8980\n",
      "Epoch 137/150\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.1603 - accuracy: 0.9286\n",
      "Epoch 138/150\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.3646 - accuracy: 0.8571\n",
      "Epoch 139/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1332 - accuracy: 0.9490\n",
      "Epoch 140/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.1390 - accuracy: 0.9592\n",
      "Epoch 141/150\n",
      "98/98 [==============================] - 2s 21ms/step - loss: 0.1881 - accuracy: 0.9286\n",
      "Epoch 142/150\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.1986 - accuracy: 0.9388\n",
      "Epoch 143/150\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.2248 - accuracy: 0.9082\n",
      "Epoch 144/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2745 - accuracy: 0.8673\n",
      "Epoch 145/150\n",
      "98/98 [==============================] - 2s 20ms/step - loss: 0.2538 - accuracy: 0.8776\n",
      "Epoch 146/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.3349 - accuracy: 0.8980\n",
      "Epoch 147/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2440 - accuracy: 0.8571\n",
      "Epoch 148/150\n",
      "98/98 [==============================] - 2s 19ms/step - loss: 0.2334 - accuracy: 0.9388\n",
      "Epoch 149/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0914 - accuracy: 0.9796\n",
      "Epoch 150/150\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.1164 - accuracy: 0.9592\n"
     ]
    }
   ],
   "source": [
    "results = model.fit_generator(train_image_gen,epochs=150,steps_per_epoch=98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4d74320",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8335fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('model_test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e40acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 98 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From C:\\Adaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Adaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\Japoka\\AppData\\Local\\Temp\\tmpc8q13y1z\\assets\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the test model\n",
    "test_gen=ImageDataGenerator(dtype='float32')\n",
    "test_image_gen=test_gen.flow_from_directory(\"data\",target_size=(64,64),color_mode='grayscale',batch_size=1)\n",
    "\n",
    "images_array = test_image_gen[0][0]\n",
    "labels_array = test_image_gen[0][1]\n",
    "for i in range(1,98):\n",
    "    images_array = np.append(images_array,test_image_gen[i][0])\n",
    "    labels_array = np.append(labels_array,test_image_gen[i][1])\n",
    "\n",
    "images_array = images_array.reshape(98,64,64,1)\n",
    "images_array = images_array.astype('float32')\n",
    "images_array = (images_array - 128.0) / 128\n",
    "\n",
    "labels_done = []\n",
    "labels_array = labels_array.reshape(98,3)\n",
    "for i in range(len(labels_array)):\n",
    "    for j in range(0,3):\n",
    "        if(labels_array[i][j]):\n",
    "            labels_done = np.append(labels_done,j)\n",
    "\n",
    "test_labels = labels_done\n",
    "labels_done = to_categorical(labels_done, 3, dtype = 'float32')\n",
    "\n",
    "#convert model into TFLM format\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "#preprocess representative images\n",
    "preprocessed_test_images = images_array\n",
    "preprocessed_test_images = tf.cast(preprocessed_test_images, tf.float32)\n",
    "tflite_ds = tf.data.Dataset.from_tensor_slices((preprocessed_test_images)).batch(1) #construct a dataset \n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value in tflite_ds.take(20):\n",
    "        yield [input_value]\n",
    "    \n",
    "converter.representative_dataset = representative_data_gen\n",
    "\n",
    "#convert model\n",
    "converted_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b96739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333312"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "generated_dir = pathlib.Path(\"generated/\")\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\n",
    "converted_model_file = generated_dir/\"test_model_int8.tflite\"\n",
    "converted_model_file.write_bytes(converted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c685684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167ed10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0078125 0\n",
      "0.00390625 -128\n"
     ]
    }
   ],
   "source": [
    "max_samples = 80\n",
    "input_scale, input_zero_point = interpreter.get_input_details()[0]['quantization']\n",
    "print(input_scale,input_zero_point)\n",
    "output_scale, output_zero_point = interpreter.get_output_details()[0]['quantization']\n",
    "print(output_scale,output_zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "237556a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\n",
    "def evaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    \n",
    "    scale, zero_point = interpreter.get_input_details()[0]['quantization']\n",
    "\n",
    "    prediction_values = []\n",
    "    output_buffer = []\n",
    "    #only consider the result having strong confidence(?%) to reduce lossing accuracy\n",
    "    higher_threshold = 0\n",
    "    lowwer_threshold = 0\n",
    "    \n",
    "    for test_image in preprocessed_test_images[:max_samples]:\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0) #.astype(np.float32)\n",
    "        test_image = np.int8(test_image / scale + zero_point)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Find the answer with highest probability\n",
    "        output = interpreter.tensor(output_index)\n",
    "        output_buffer = np.append(output_buffer,output()[0][1])\n",
    "        result = np.argmax(output()[0])\n",
    "        prediction_values.append(result)\n",
    "        \n",
    "    accurate_count_k = 0\n",
    "    num_data_used = 0\n",
    "    \n",
    "    for index in range(len(prediction_values)):\n",
    "        if(output_buffer[index]>higher_threshold or output_buffer[index]<lowwer_threshold):\n",
    "            num_data_used +=1\n",
    "            if prediction_values[index] == test_labels[index]:\n",
    "                accurate_count_k +=1\n",
    "                \n",
    "    #print(num_data_used)    \n",
    "\n",
    "    accuracy = accurate_count_k * 1.0 / num_data_used\n",
    "    \n",
    "    return accuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4945741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.75%\n"
     ]
    }
   ],
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa40f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
